[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nOctober 15, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nSuavização de Rótulos\n\n\n\n\n\n\nregularization\n\n\ndeep learning\n\n\nneural networks\n\n\ntraining\n\n\n\nModelos podem errar por excesso de confiança. Suavizar os rótulos pode ser uma solução.\n\n\n\n\n\nOctober 15, 2024\n\n\nJosé Geraldo de Carvalho Pereira\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nOctober 12, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/suavizacao-de-rotulos/index.html",
    "href": "posts/suavizacao-de-rotulos/index.html",
    "title": "Suavização de Rótulos",
    "section": "",
    "text": "Redes neurais artificiais profundas são modelos com enorme capacidade de expressar relações existentes nos dados. Ao mesmo tempo que isso confere poder e as tornam úteis para tarefas complexas e variadas, parte dessas relações podem ser apenas “ruídos”. Em outras palavras, coincidências podem ser confundidas pelos modelos como sendo relações verdadeiras, o que acaba sendo algo comum, principalmente quando o conjunto de dados é pequeno ou a amostra contém viéses significativos. A consequência mais direta desse tipo de problema aparece na forma de sobre-ajuste (overfitting). No entanto, há consequências mais sutis como o excesso de confiança do modelo (overconfidence). \nO excesso de confiança está relacionado a uma estimativa ruim da incerteza do modelo sobre o resultado. Um bom modelo, não é apenas aquele que erra pouco durante os testes, mas o que diz o quão certo ou incerto ele está sobre o resultado apresentado.\nA técnica de suavização dos rótulos (label-smoothing) é um método de regularização aplicado com o objetivo de reduzir tanto a ocorrência de sobre-ajuste quanto o excesso de confiança do modelo."
  },
  {
    "objectID": "posts/suavizacao-de-rotulos/index.html#motivação",
    "href": "posts/suavizacao-de-rotulos/index.html#motivação",
    "title": "Suavização de Rótulos",
    "section": "",
    "text": "Redes neurais artificiais profundas são modelos com enorme capacidade de expressar relações existentes nos dados. Ao mesmo tempo que isso confere poder e as tornam úteis para tarefas complexas e variadas, parte dessas relações podem ser apenas “ruídos”. Em outras palavras, coincidências podem ser confundidas pelos modelos como sendo relações verdadeiras, o que acaba sendo algo comum, principalmente quando o conjunto de dados é pequeno ou a amostra contém viéses significativos. A consequência mais direta desse tipo de problema aparece na forma de sobre-ajuste (overfitting). No entanto, há consequências mais sutis como o excesso de confiança do modelo (overconfidence). \nO excesso de confiança está relacionado a uma estimativa ruim da incerteza do modelo sobre o resultado. Um bom modelo, não é apenas aquele que erra pouco durante os testes, mas o que diz o quão certo ou incerto ele está sobre o resultado apresentado.\nA técnica de suavização dos rótulos (label-smoothing) é um método de regularização aplicado com o objetivo de reduzir tanto a ocorrência de sobre-ajuste quanto o excesso de confiança do modelo."
  },
  {
    "objectID": "posts/suavizacao-de-rotulos/index.html#explicação-intuitiva",
    "href": "posts/suavizacao-de-rotulos/index.html#explicação-intuitiva",
    "title": "Suavização de Rótulos",
    "section": "Explicação intuitiva",
    "text": "Explicação intuitiva\nDurante o treinamento de modelos para tarefas de classificação é comum que os dados utilizados tenham o rótulo \\(y\\) da classe a qual pertencem, sendo \\(y \\in \\\\{0, 1\\\\}\\) para classificação binária ou no formato de um vetor one-hot encoding para classificação em uma dentre múltiplas classes. Esse modo de representação contém, além da classe, a confiança sobre aquele rótulo - “Eu tenho certeza que é A \\((y=1)\\)” ou “Eu tenho certeza que não é A \\((y=0)\\)”. Assim, além da classe correta, fornecemos durante o treinamento a informação de absoluta certeza ou, dito de outra forma, nenhuma incerteza.\nConsequentemente, podemos reduzir possíveis excessos de confiança do modelo através dos rótulos. Para fazermos isso, o que anteriormente era certeza passa a conter uma leve incerteza - “Eu estou quase certo que é A \\((y=0.9)\\)” ou “Eu estou quase certo que não é A \\((y=0.1)\\)”. Isso é a suavização dos rótulos ou label smoothing! Esse tipo de representação dos rótulos é chamada de suave (soft), enquanto a tradicional, apenas com 0s e 1s, é a rígida (hard).\n**inserir imagem*"
  },
  {
    "objectID": "posts/suavizacao-de-rotulos/index.html#detalhamento",
    "href": "posts/suavizacao-de-rotulos/index.html#detalhamento",
    "title": "Suavização de Rótulos",
    "section": "Detalhamento",
    "text": "Detalhamento\n\n\nA Inception-v3 foi desenvolvida para ser aplicada na classificação de imagens do dataset ImageNet. Como o dataset possui 1000 classes temos \\(K=1000\\).\nNa literatura, a referência primária da técnica de suavização de rótulos é o trabalho de Szegedy et al. (2016). Nesse trabalho, no qual é descrita a arquitetura da rede neural Inception-v3, os autores suavizaram os rótulos uniformemente. Assim, a classe correta de uma entrada \\(x\\) tinha um rótulo \\(y = 1 - \\epsilon + \\frac{\\epsilon}{K}\\) e cada uma das outras 999 classes incorretas \\((K-1)\\) possuiam o rótulo \\(\\frac{\\epsilon}{K}\\).\n\n\n\nNo livro Deep Learning (Goodfellow, Courville, Bengio) dizem que a técnica de suavização dos rótulos.\nA suavização uniforme realizada por Szegedy ainda é bastante comum, entretanto, outras formas de suavização foram publicadas nos últimos anos. Como por exemplo:\n\nIncerteza derivada de especialistas;\nIncerteza extraída de um modelo maior para ser utilizada no treinamento de um modelo menor (destilação);\nIncerteza para adaptar um problema de ranqueamento em classificação.\n\nEm um trabalho de pesquisa que tenho conduzido, mas ainda não publicado, tenho utilizado a técnica de suavização de rótulos para controlar a incerteza quanto predispodisição genética de um indivíduo ter diabetes tipo 2 de maneira dependente da idade. Assim, para um jovem adulto não diabético temos maior incerteza sobre sua predisposição genética dado que ele poderá apresentar diabetes no futuro. Por outro lado, um indivíduo não diabético e com 70 anos muito provavelmente tem baixa predisposição genética. Já para os indivíduos diabéticos tipo 2 a incerteza não é dependente da idade uma vez que a predisposição está confirmada, restando apenas a incerteza quanto qual é a magnitude do efeito genético e do ambiental."
  },
  {
    "objectID": "posts/suavizacao-de-rotulos/index.html#referências",
    "href": "posts/suavizacao-de-rotulos/index.html#referências",
    "title": "Suavização de Rótulos",
    "section": "Referências",
    "text": "Referências\nSzegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., & Wojna, Z. (2015). Rethinking the Inception Architecture for Computer Vision. arXiv:1512.00567 [cs]. link"
  }
]